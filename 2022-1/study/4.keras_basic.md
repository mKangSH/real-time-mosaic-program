# Neural network

It has more than one layer containing one more neuron(node).

Inside of neuron, weight that is updated by model training exists.

# Dense layer(Fully Connected Layer)

Status that all neuron interconnect themselves between each layer.

Be able to direct activation function for activation parameter.

Input value : 1 rank tensor

# Flatten layer

It changes multidimensional data to 1 rank tensor.

Use tf.keras.layers.Flatten() function.

# Activation Function

(_image_) not found

It changes input to nonlinear output.

ex) sigmoid, tanh(Hyperbolic Tangent), ReLU(Rectified Unit), Leaky ReLU, etc.
  - Use the 'sigmoid' activation function of output node if there is only one output node.
  - Use the 'softmax' activation function of output node if there are more than one output node.

[Activation Function document](https://www.tensorflow.org/api_docs/python/tf/keras/activations)

